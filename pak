#!/bin/bash
# A text-based packer that bundles files (with metadata) into a single archive.
# Output is designed to be easily parsed text, suitable for LLMs.
# NOW WITH TOKEN COMPRESSION CAPABILITIES AND SHORTER ARCHIVE IDs!
#
# Version: 2.1.4
#
# New in 2.1.4:
#  - pack_file now explicitly handles empty files to avoid "Skipping compression" messages for them.
#
# New in 2.1.3:
#  - Major overhaul of main argument parsing logic for robust handling of global options
#    (like --compress-level) regardless of their position relative to the pack command/files.
#
# (Previous version history omitted for brevity)

VERSION="2.1.4"

# Default compression settings
COMPRESSION_LEVEL="none"
MAX_TOKENS=0  # 0 = unlimited
CURRENT_TOKEN_COUNT=0

# Priority file extensions for smart mode
PRIORITY_EXTENSIONS=(".py" ".js" ".ts" ".md" ".sh" ".cpp" ".h" ".java" ".go" ".rs")

# Semantic exclusion patterns
SEMANTIC_EXCLUDES=(
    "*.min.js" "*.min.css" "*.bundle.*" "*lock*" "*.log" "*cache*" "*dist/*"
    "*build/*" "*.pyc" "*__pycache__*" "*generated*" "*vendor/*" "*node_modules/*"
    "*.png" "*.jpg" "*.jpeg" "*.gif" "*.bmp" "*.tiff" "*.ico" "*.svg"
    "*.zip" "*.tar" "*.gz" "*.bz2" "*.rar" "*.7z" "*.tgz"
    "*.pdf" "*.doc" "*.docx" "*.xls" "*.xlsx" "*.ppt" "*.pptx" "*.odt" "*.ods" "*.odp"
    "*.o" "*.a" "*.so" "*.dll" "*.exe" "*.jar" "*.class" "*.swp" "*.bak" "*.tmp"
    "*.DS_Store" "*.iml" "*.ipr" "*.iws" ".idea/*" ".vscode/*" "*.beam" "*.elf"
    "*.mp3" "*.mp4" "*.avi" "*.mov" "*.wav" "*.webm"
    "*.db" "*.sqlite" "*.sqlite3" "*.dump"
    "*.woff" "*.woff2" "*.ttf" "*.eot" # Font files
    "*/.git/*" ".git"
    "*/.hg/*" ".hg"
    "*/.svn/*" ".svn"
)

# Marker prefixes
PAK_ID_LINE_PREFIX="__PAK_ID__:"
PAK_UUID_LINE_PREFIX="__PAK_UUID__:"
PAK_FILE_START_PREFIX="__PAK_FILE_"
PAK_DATA_START_PREFIX="__PAK_DATA_"
PAK_DATA_END_PREFIX="__PAK_DATA_"

PAK_FILE_START=""
PAK_DATA_START=""
PAK_DATA_END=""

define_markers() {
    local id="$1"
    PAK_FILE_START="${PAK_FILE_START_PREFIX}${id}_START__"
    PAK_DATA_START="${PAK_DATA_START_PREFIX}${id}_START__"
    PAK_DATA_END="${PAK_DATA_END_PREFIX}${id}_END__"
}

estimate_tokens() {
    local file="$1"
    if [ -f "$file" ]; then
        local size
        if command -v stat &> /dev/null; then
            size=$(stat -c%s "$file" 2>/dev/null || echo "0")
        else
            size=$(wc -c < "$file" 2>/dev/null || echo "0")
        fi
        echo $((size / 4))
    else
        echo "0"
    fi
}

calculate_file_importance() {
    local file="$1"
    local score=0
    local filename=$(basename "$file")
    local extension="${filename##*.}"
    case ".$extension" in
        .py|.js|.ts|.cpp|.h|.java|.go|.rs) score=$((score + 10)) ;;
        .md|.rst) if [[ "$filename" =~ ^(README|readme|CHANGELOG) ]]; then score=$((score + 15)); else score=$((score + 5)); fi ;;
        .sh|.bash) score=$((score + 8)) ;;
        .json|.yml|.yaml|.toml) score=$((score + 3)) ;;
        *) score=$((score + 1)) ;;
    esac
    if [[ "$filename" =~ ^(main|index|app|core|setup|config|dockerfile|makefile|requirements|package\.json|gemfile|build\.gradle)($|\.) ]]; then score=$((score + 7)); fi
    if [[ "$file" =~ (test|Test|spec|fixture|mock|stub) ]]; then score=$((score - 5)); fi
    if [ "$score" -lt 0 ]; then score=0; fi
    echo "$score"
}

matches_semantic_excludes() {
    local file_path="$1"
    for pattern in "${SEMANTIC_EXCLUDES[@]}"; do
        if [[ "$file_path" == $pattern ]]; then return 0; fi
    done
    return 1
}

PACK_INCLUDE_EXTENSIONS=()

matches_extension_filter() {
    local file="$1"
    if [ ${#PACK_INCLUDE_EXTENSIONS[@]} -eq 0 ]; then return 0; fi
    local filename_only=$(basename "$file")
    for ext_filter_item in "${PACK_INCLUDE_EXTENSIONS[@]}"; do
        if [[ "$ext_filter_item" == .* ]]; then
            if [[ "$filename_only" == *"$ext_filter_item" ]]; then return 0; fi
        else
            if [[ "$filename_only" == "$ext_filter_item" ]] || [[ "$filename_only" == *".$ext_filter_item" ]]; then return 0; fi
        fi
    done
    return 1
}

compress_content_light() {
    local file_path_or_stdin="$1"
    sed -E '/^[[:space:]]*$/d' "$file_path_or_stdin" | sed -E 's/^[[:space:]]+//' | sed -E 's/[[:space:]]+$//'
}

compress_content_medium() {
    local file="$1"
    local extension="${file##*.}"
    local ext_lower=$(echo "$extension" | tr '[:upper:]' '[:lower:]')
    case "$ext_lower" in
        py|js|ts|java|c|cpp|h|cs|go|rs|php|rb|pl|swift|kt|kts|sh|bash)
            sed -E \
                -e '1{/^#![^\n]*$/b}' \
                -e '/^[[:space:]]*\/\//d' \
                -e '/^[[:space:]]*#/d' \
                -e '/^[[:space:]]*\/\*.*\*\//d' \
                -e '/^[[:space:]]*<!--.*-->/d' \
                "$file" | compress_content_light /dev/stdin ;;
        *) compress_content_light "$file" ;;
    esac
}

compress_content_aggressive() {
    local file="$1"
    local extension="${file##*.}"
    local ext_lower=$(echo "$extension" | tr '[:upper:]' '[:lower:]')
    local content=""
    case "$ext_lower" in
        py) content=$(grep -Eahn --text '^\s*(def |class |import |from |@|\s*"""|\s*#\s*(TODO|FIXME|NOTE|OPTIMIZE|IMPORTANT|HACK|XXX))' "$file" | head -n 100) ;;
        js|ts) content=$(grep -Eahn --text '^\s*(function |const |let |var |export |import |class |@|\/\*\*|\*\/|\s*\/\/\s*(TODO|FIXME|NOTE|OPTIMIZE|IMPORTANT|HACK|XXX))' "$file" | head -n 100) ;;
        c|cpp|h|java|go|rs|cs) content=$(grep -Eahn --text '^\s*(public |private |protected |static |final |func |fn |void |int |long |char |string |struct |class |interface |enum |package |import |#include|#pragma|\/\*\*|\*\/|\s*\/\/\s*(TODO|FIXME|NOTE|OPTIMIZE|IMPORTANT|HACK|XXX))' "$file" | head -n 100) ;;
        md|rst) content=$(head -n 150 "$file") ;;
        sh|bash) content=$(grep -Ev '^[[:space:]]*#|^[[:space:]]*$' "$file" | head -n 100) ;;
        json|yml|yaml|toml|xml|html|css) content=$(head -n 200 "$file") ;;
        *) compress_content_medium "$file"; return ;;
    esac
    if [ -z "$content" ] && [ -s "$file" ]; then
        compress_content_medium "$file"
    else
        echo "$content"
    fi
}

pack_file() {
    local file="$1"
    local current_archive_id="$2"
    local size lines compressed_content estimated_tokens

    if ! size=$(stat -c%s "$file" 2>/dev/null || wc -c < "$file" 2>/dev/null); then
        echo "Warning: Could not get size for '$file'. Skipping." >&2; return;
    fi

    # Handle empty files first
    if [ "$size" -eq 0 ]; then
        compressed_content="" # Empty content for empty files
        # No "Skipping compression" message for empty files as there's nothing to compress
    else
        local is_text=false
        if command -v file &> /dev/null; then
            if LANG=C file "$file" | grep -q "text"; then
                is_text=true
            elif LANG=C file "$file" | grep -q "empty"; then # if file reports "empty" but size > 0 (e.g. whitespace only)
                is_text=true # Treat as text for compression (will likely become empty)
            fi
        else
            case "${file##*.}" in
                py|js|ts|md|sh|cpp|h|java|go|rs|json|yml|yaml|toml|txt|xml|html|css|c|cs|php|rb|pl|swift|kt|kts) is_text=true ;;
            esac
        fi

        if $is_text; then
            case "$COMPRESSION_LEVEL" in
                "light") compressed_content=$(compress_content_light "$file") ;;
                "medium") compressed_content=$(compress_content_medium "$file") ;;
                "aggressive") compressed_content=$(compress_content_aggressive "$file") ;;
                *) compressed_content=$(cat "$file") ;; # none
            esac
        else # Not identified as text, or 'file' command unavailable and not a known text ext
            if [ "$COMPRESSION_LEVEL" != "none" ]; then # Only show message if compression was attempted
                 echo "Info: Skipping compression for non-text or unknown file type '$file'." >&2
            fi
            compressed_content=$(cat "$file") # Pack as-is
        fi
    fi

    estimated_tokens=$(printf "%s" "$compressed_content" | wc -c | awk '{print int($1/4)}')
    if [ "$MAX_TOKENS" -gt 0 ] && [ $((CURRENT_TOKEN_COUNT + estimated_tokens)) -gt "$MAX_TOKENS" ]; then
        echo "Info: Skipping '$file' (token limit: $MAX_TOKENS. Current: $CURRENT_TOKEN_COUNT, File: $estimated_tokens)" >&2
        return
    fi
    CURRENT_TOKEN_COUNT=$((CURRENT_TOKEN_COUNT + estimated_tokens))
    lines=$(printf "%s" "$compressed_content" | wc -l)

    echo "$PAK_FILE_START"
    echo "Path: $file"
    echo "Size: $size"
    echo "Lines: $lines"
    echo "Tokens: $estimated_tokens"
    echo "$PAK_DATA_START"
    printf "%s" "$compressed_content"
    local last_char_is_newline=false
    if [ -n "$compressed_content" ]; then
      if [[ "${compressed_content: -1}" == $'\n' ]]; then last_char_is_newline=true; fi
      if ! $last_char_is_newline; then echo; fi
    else
      echo # Ensure PAK_DATA_END is on a new line if content was empty
    fi
    echo "$PAK_DATA_END"
}

archive_id_for_session=""

pack_smart() {
    local files_and_dirs_to_pack=("$@")
    local file_list=() importance_list=()
    for item in "${files_and_dirs_to_pack[@]}"; do
        if [ -f "$item" ]; then
            if ! matches_semantic_excludes "$item" && matches_extension_filter "$item"; then
                local importance=$(calculate_file_importance "$item")
                local original_tokens=$(estimate_tokens "$item")
                importance_list+=("$importance:$original_tokens:$item")
            fi
        elif [ -d "$item" ]; then
            find_exclude_opts=(-path "*/.git" -o -path "*/.hg" -o -path "*/.svn" -o -name "*.pak")
            while IFS= read -r -d '' file; do
                if ! matches_semantic_excludes "$file" && matches_extension_filter "$file"; then
                    local importance=$(calculate_file_importance "$file")
                    local original_tokens=$(estimate_tokens "$file")
                    importance_list+=("$importance:$original_tokens:$file")
                fi
            done < <(find "$item" \( "${find_exclude_opts[@]}" \) -prune -o -type f -print0)
        fi
    done
    IFS=$'\n' sorted_files=($(printf '%s\n' "${importance_list[@]}" | sort -t: -k1,1nr -k2,2n)); unset IFS
    echo "Info: Found ${#sorted_files[@]} files matching filters. Smart compression (budget: $MAX_TOKENS tokens)..." >&2
    for entry in "${sorted_files[@]}"; do
        local importance="${entry%%:*}"
        local original_tokens_for_entry="${entry#*:}"; original_tokens_for_entry="${original_tokens_for_entry%%:*}"
        local filepath="${entry##*:}"
        local temp_compression_level initial_compression_level_for_smart="light"
        if [ "$MAX_TOKENS" -gt 0 ]; then
            local remaining_budget=$((MAX_TOKENS - CURRENT_TOKEN_COUNT))
            if [ "$remaining_budget" -le 0 ]; then echo "Info: Token budget exhausted." >&2; break; fi
            if [ "$importance" -lt 5 ] || ( [ "$importance" -lt 8 ] && [ "$original_tokens_for_entry" -gt $((remaining_budget / 3)) ] ); then temp_compression_level="aggressive";
            elif [ "$importance" -lt 8 ] || ( [ "$importance" -lt 10 ] && [ "$original_tokens_for_entry" -gt $((remaining_budget / 2)) ] ); then temp_compression_level="medium";
            else temp_compression_level="$initial_compression_level_for_smart"; fi
        else
             if [ "$importance" -lt 5 ]; then temp_compression_level="aggressive";
             elif [ "$importance" -lt 8 ]; then temp_compression_level="medium";
             else temp_compression_level="$initial_compression_level_for_smart"; fi
        fi
        local original_script_compression_level_backup="$COMPRESSION_LEVEL"
        COMPRESSION_LEVEL="$temp_compression_level"
        pack_file "$filepath" "$archive_id_for_session"
        COMPRESSION_LEVEL="$original_script_compression_level_backup"
        if [ "$MAX_TOKENS" -gt 0 ] && [ "$CURRENT_TOKEN_COUNT" -ge "$MAX_TOKENS" ]; then
            echo "Info: Token limit reached. Processed up to '$filepath'." >&2; break;
        fi
    done
}

pack() {
    PACK_INCLUDE_EXTENSIONS=()
    local final_files_dirs_to_pack=()
    local using_smart_mode=false
    if [ "$COMPRESSION_LEVEL" = "smart" ]; then using_smart_mode=true; fi
    local args_for_pack_function_processing=("$@")
    while [ "${#args_for_pack_function_processing[@]}" -gt 0 ]; do
        local arg="${args_for_pack_function_processing[0]}"
        case "$arg" in
            --ext)
                unset 'args_for_pack_function_processing[0]'; args_for_pack_function_processing=("${args_for_pack_function_processing[@]}")
                if [ "${#args_for_pack_function_processing[@]}" -eq 0 ] || [[ "${args_for_pack_function_processing[0]}" == --* ]]; then
                    echo "Error: --ext requires at least one extension argument (e.g., .py .md)" >&2; exit 1;
                fi
                while [ "${#args_for_pack_function_processing[@]}" -gt 0 ] && ! [[ "${args_for_pack_function_processing[0]}" == --* ]]; do
                    PACK_INCLUDE_EXTENSIONS+=("${args_for_pack_function_processing[0]}")
                    unset 'args_for_pack_function_processing[0]'; args_for_pack_function_processing=("${args_for_pack_function_processing[@]}")
                done ;;
            *)
                final_files_dirs_to_pack+=("$arg")
                unset 'args_for_pack_function_processing[0]'; args_for_pack_function_processing=("${args_for_pack_function_processing[@]}") ;;
        esac
    done
    if [ "${#final_files_dirs_to_pack[@]}" -eq 0 ]; then
        script_name=$(basename "$0")
        echo "Usage: $script_name --pack [GLOBAL_OPTS] [--ext .ext1] <files/dirs>" >&2; exit 1;
    fi
    archive_id_for_session=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 12)
    if [ -z "$archive_id_for_session" ]; then echo "Error: Failed to generate Archive ID." >&2; exit 1; fi
    echo "${PAK_ID_LINE_PREFIX}${archive_id_for_session}"
    echo "# Archive created with pak v$VERSION"
    echo "# Archive ID: $archive_id_for_session"
    echo "# Compression Mode: $COMPRESSION_LEVEL"
    if [ "${#PACK_INCLUDE_EXTENSIONS[@]}" -gt 0 ]; then echo "# Extension Filter: ${PACK_INCLUDE_EXTENSIONS[*]}"; fi
    if [ "$MAX_TOKENS" -gt 0 ]; then echo "# Token Limit: $MAX_TOKENS"; fi
    define_markers "$archive_id_for_session"
    if $using_smart_mode; then
        pack_smart "${final_files_dirs_to_pack[@]}"
    else
        for item in "${final_files_dirs_to_pack[@]}"; do
            if [ -f "$item" ]; then
                if ! matches_semantic_excludes "$item" && matches_extension_filter "$item"; then
                    pack_file "$item" "$archive_id_for_session"
                fi
            elif [ -d "$item" ]; then
                find_exclude_opts=(-path "*/.git" -o -path "*/.hg" -o -path "*/.svn" -o -name "*.pak")
                while IFS= read -r -d '' file; do
                    if ! matches_semantic_excludes "$file" && matches_extension_filter "$file"; then # Corrected from "$item"
                        pack_file "$file" "$archive_id_for_session"
                    fi
                done < <(find "$item" \( "${find_exclude_opts[@]}" \) -prune -o -type f -print0)
            fi
            if [ "$MAX_TOKENS" -gt 0 ] && [ "$CURRENT_TOKEN_COUNT" -ge "$MAX_TOKENS" ]; then
                echo "Info: Token limit reached." >&2; break;
            fi
        done
    fi
    echo "# Archive complete. Total estimated tokens: $CURRENT_TOKEN_COUNT" >&2
}

list_archive() {
    local archive_file="$1"; local script_name=$(basename "$0")
    if [ ! -f "$archive_file" ]; then echo "Error: Archive file not found: $archive_file" >&2; exit 1; fi
    local first_line; read -r first_line < "$archive_file"; local archive_id_from_file=""
    if [[ "$first_line" == "${PAK_ID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_ID_LINE_PREFIX}}";
    elif [[ "$first_line" == "${PAK_UUID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_UUID_LINE_PREFIX}}"; echo "Info: Reading legacy UUID archive." >&2;
    else echo "Error: Not a valid pak archive (missing ID line)." >&2; return 1; fi
    if [ -z "$archive_id_from_file" ]; then echo "Error: Could not extract archive ID." >&2; exit 1; fi
    define_markers "$archive_id_from_file"
    tail -n +2 "$archive_file" | awk \
        -v FILE_START="$PAK_FILE_START" -v DATA_START="$PAK_DATA_START" \
    '
    /^#.*/ {next}
    $0 == FILE_START {h=1; p=""; s=""; t=""; next}
    h && match($0, /^Path: (.*)/, arr) { p=arr[1]; next }
    h && match($0, /^Size: (.*)/, arr) { s=arr[1]; next }
    h && match($0, /^Tokens: (.*)/, arr) { t=arr[1]; next }
    h && $0 == DATA_START { if(p){printf "%s (Size: %s", p, s; if(t!="")printf ", Tokens: %s",t; printf ")\n"} h=0; p="";s="";t=""; next}
    h==0 {next}
    '
}

verify_archive() {
    local archive_file="$1"; local script_name=$(basename "$0"); echo "Verifying archive '$archive_file'..."
    if [ ! -f "$archive_file" ]; then echo "Error: Archive file not found: $archive_file" >&2; exit 1; fi
    local first_line; read -r first_line < "$archive_file"; local archive_id_from_file=""; local fmt_msg="pak v2.1+ (short ID)"
    if [[ "$first_line" == "${PAK_ID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_ID_LINE_PREFIX}}";
    elif [[ "$first_line" == "${PAK_UUID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_UUID_LINE_PREFIX}}"; fmt_msg="pak v2.0 (UUID)"; echo "Info: Verifying legacy UUID archive." >&2;
    else echo "Error: Not valid pak archive (missing ID line)." >&2; return 1; fi
    if [ -z "$archive_id_from_file" ]; then echo "Error: Could not extract archive ID." >&2; return 1; fi
    echo "Archive format: $fmt_msg, ID: $archive_id_from_file"; define_markers "$archive_id_from_file"
    local total_files=0; local total_declared_tokens=0; local in_header=0
    { IFS= read -r _; while IFS= read -r line; do
        if [[ "$line" == "#"* ]] && [ "$in_header" -eq 0 ]; then continue; fi
        if [[ "$line" == "$PAK_FILE_START" ]]; then total_files=$((total_files + 1)); in_header=1;
        elif [[ "$line" == "$PAK_DATA_START" ]]; then in_header=0;
        elif [[ "$line" == "Tokens: "* ]] && [ "$in_header" -eq 1 ]; then
            local tokens_val="${line#Tokens: }"; tokens_val="${tokens_val%%[^0-9]*}"
            if [[ "$tokens_val" =~ ^[0-9]+$ ]]; then total_declared_tokens=$((total_declared_tokens + tokens_val)); fi
        fi; done; } < "$archive_file"
    echo "Verification complete: Found $total_files files, total declared tokens: ~$total_declared_tokens"
}

unpack_archive() {
    local archive_file="$1"; local outdir="${2:-.}"; local script_name=$(basename "$0"); echo "Unpacking '$archive_file' to '$outdir'..."
    if [ ! -f "$archive_file" ]; then echo "Error: Archive file not found: $archive_file" >&2; exit 1; fi
    local first_line; read -r first_line < "$archive_file"; local archive_id_from_file=""
    if [[ "$first_line" == "${PAK_ID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_ID_LINE_PREFIX}}";
    elif [[ "$first_line" == "${PAK_UUID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_UUID_LINE_PREFIX}}"; echo "Info: Unpacking legacy UUID archive." >&2;
    else echo "Error: Not a valid pak archive (missing ID line)." >&2; return 1; fi
    if [ -z "$archive_id_from_file" ]; then echo "Error: Could not extract archive ID." >&2; return 1; fi
    define_markers "$archive_id_from_file"; mkdir -p "$outdir"
    local current_path=""; local in_data_block=false; local temp_file_for_content=""
    { IFS= read -r _; while IFS= read -r line; do
        if ! $in_data_block && [[ "$line" == "#"* ]]; then continue; fi
        if $in_data_block; then
            if [[ "$line" == "$PAK_DATA_END" ]]; then
                in_data_block=false
                if [ -n "$current_path" ] && [ -n "$temp_file_for_content" ]; then
                    local full_out_path="$outdir/$current_path"; local file_dir=$(dirname "$full_out_path")
                    if ! mkdir -p "$file_dir"; then echo "Error: Could not create dir $file_dir" >&2; rm "$temp_file_for_content"; exit 1; fi
                    if [ -f "$temp_file_for_content" ]; then
                         if mv "$temp_file_for_content" "$full_out_path"; then echo "Extracted: $full_out_path"; else echo "Error: mv failed for $full_out_path" >&2; rm "$temp_file_for_content"; fi
                    else echo "Warning: Temp file $temp_file_for_content not found for $current_path" >&2; fi
                    temp_file_for_content=""; current_path=""
                else echo "Error: Data end without path/temp file." >&2; if [ -n "$temp_file_for_content" ] && [ -f "$temp_file_for_content" ]; then rm "$temp_file_for_content"; fi; fi
            else if [ -n "$temp_file_for_content" ]; then echo "$line" >> "$temp_file_for_content"; fi; fi
        elif [[ "$line" == "$PAK_FILE_START" ]]; then
            current_path=""; if [ -n "$temp_file_for_content" ] && [ -f "$temp_file_for_content" ]; then rm "$temp_file_for_content"; fi
            temp_file_for_content=$(mktemp "${outdir}/.pak_tmp_XXXXXX")
            if [ $? -ne 0 ] || [ -z "$temp_file_for_content" ]; then echo "Error: mktemp failed." >&2; exit 1; fi
        elif [[ "$line" == "Path: "* ]]; then current_path="${line#Path: }"; current_path=$(echo "$current_path" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//');
        elif [[ "$line" == "$PAK_DATA_START" ]]; then
            if [ -z "$current_path" ]; then echo "Error: Data start without Path." >&2; if [ -n "$temp_file_for_content" ]; then rm "$temp_file_for_content"; fi; exit 1; fi
            if [ -z "$temp_file_for_content" ]; then echo "Error: Temp file not ready for $current_path." >&2; exit 1; fi
            in_data_block=true
        fi; done; } < "$archive_file"
    if [ -n "$temp_file_for_content" ] && [ -f "$temp_file_for_content" ]; then rm "$temp_file_for_content"; fi
    echo "Unpack complete."
}

# Main script logic
script_name=$(basename "$0")

if [ "$#" -eq 0 ]; then
    echo "pak v$VERSION - Token-optimized file archiver for LLMs"
    echo ""
    echo "Usage:"
    echo "  Pack:    $script_name [GLOBAL_OPTS] [--pack] [PACK_OPTS] <files/dirs ...> > archive.pak"
    echo "  List:    $script_name --ls <archive file>"
    echo "  Unpack:  $script_name --unpack <archive file> [--outdir dir]"
    echo "  Verify:  $script_name --verify <archive file>"
    echo ""
    echo "Global Options (can appear anywhere before other commands or pack files):"
    echo "  --compress-level LEVEL : none, light, medium, aggressive, smart (default: $COMPRESSION_LEVEL)"
    echo "  --max-tokens N         : Limit total tokens in archive (0 for unlimited, default: $MAX_TOKENS)"
    echo ""
    echo "Pack Command Specific Options (can be mixed with files/dirs for --pack):"
    echo "  --ext .ext1 .ext2 ...  : Only include files with these extensions or exact names (e.g., .py .md Makefile)"
    echo ""
    echo "Example:"
    echo "  $script_name --compress-level smart --max-tokens 16000 src/ --ext .py .md project/README.md > archive.pak"
    echo "  $script_name --pack src/ lib/ --ext .js .css --compress-level light > minimal_frontend.pak"
    exit 1
fi

declare -a PASSTHROUGH_ARGS=()
COMMAND=""

while [ "$#" -gt 0 ]; do
    case "$1" in
        --compress-level)
            if [ -z "$2" ]; then echo "Error: --compress-level requires an argument." >&2; exit 1; fi
            COMPRESSION_LEVEL="$2"
            if ! [[ "$COMPRESSION_LEVEL" =~ ^(none|light|medium|aggressive|smart)$ ]]; then
                 echo "Error: Invalid compression level '$COMPRESSION_LEVEL'." >&2; exit 1;
            fi
            shift 2; continue
            ;;
        --max-tokens)
            if [ -z "$2" ] || ! [[ "$2" =~ ^[0-9]+$ ]]; then
                echo "Error: --max-tokens requires a non-negative integer." >&2; exit 1;
            fi
            MAX_TOKENS="$2"
            shift 2; continue
            ;;
        --pack|--ls|--unpack|--verify|--version)
            if [ -n "$COMMAND" ] && [ "$COMMAND" != "$1" ]; then
                echo "Error: Cannot specify multiple main commands ('$COMMAND' and '$1')." >&2
                PASSTHROUGH_ARGS+=("$1")
                shift
            elif [ -z "$COMMAND" ]; then
                COMMAND="$1"
                shift
            else
                PASSTHROUGH_ARGS+=("$1")
                shift
            fi
            ;;
        *)
            PASSTHROUGH_ARGS+=("$1")
            shift
            ;;
    esac
done

if [ -z "$COMMAND" ]; then
    COMMAND="--pack"
fi

case "$COMMAND" in
    --pack)
        pack "${PASSTHROUGH_ARGS[@]}" ;;
    --ls)
        if [ "${#PASSTHROUGH_ARGS[@]}" -ne 1 ]; then echo "Usage: $script_name --ls <archive file>" >&2; exit 1; fi
        list_archive "${PASSTHROUGH_ARGS[0]}" ;;
    --verify)
        if [ "${#PASSTHROUGH_ARGS[@]}" -ne 1 ]; then echo "Usage: $script_name --verify <archive file>" >&2; exit 1; fi
        verify_archive "${PASSTHROUGH_ARGS[0]}" ;;
    --unpack)
        local archive_to_unpack=""
        local unpack_outdir="."
        local temp_unpack_args=("${PASSTHROUGH_ARGS[@]}")
        if [ "${#temp_unpack_args[@]}" -eq 0 ]; then echo "Usage: $script_name --unpack <archive file> [--outdir dir]" >&2; exit 1; fi
        archive_to_unpack="${temp_unpack_args[0]}"
        unset 'temp_unpack_args[0]'; temp_unpack_args=("${temp_unpack_args[@]}")
        if [ "${#temp_unpack_args[@]}" -gt 0 ] && [ "${temp_unpack_args[0]}" == "--outdir" ]; then
            if [ "${#temp_unpack_args[@]}" -lt 2 ]; then echo "Error: --outdir requires a directory path." >&2; exit 1; fi
            unpack_outdir="${temp_unpack_args[1]}"
            unset 'temp_unpack_args[0]' 'temp_unpack_args[1]'; temp_unpack_args=("${temp_unpack_args[@]}")
        fi
        if [ "${#temp_unpack_args[@]}" -gt 0 ]; then echo "Error: Unknown arguments for --unpack: ${temp_unpack_args[*]}" >&2; exit 1; fi
        unpack_archive "$archive_to_unpack" "$unpack_outdir" ;;
    --version)
        if [ "${#PASSTHROUGH_ARGS[@]}" -gt 0 ]; then echo "Warning: --version does not take arguments: ${PASSTHROUGH_ARGS[*]}" >&2; fi
        echo "pak version $VERSION"
        echo "Features: token compression, short IDs, semantic filtering, smart prioritization, extension filtering" ;;
    *)
        echo "Internal Error: Unhandled command '$COMMAND'. Args: ${PASSTHROUGH_ARGS[*]}" >&2
        exit 1 ;;
esac

exit 0
