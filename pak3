#!/bin/bash
# pak v2.2.9 - Token-optimized file archiver with AST-based compression
# Enhanced version with automatic tree-sitter installation and intelligent compression
# Works out-of-the-box on Ubuntu 24+ and other Linux distributions

VERSION="2.2.9" # Updated version number

_CACHED_AST_STATUS="" # Global variable to store the determined AST status ("true" or "false")
_AST_STATUS_DETERMINED="false" # Global flag indicating if the status has been determined
_PAK_SCRIPT_DIR="" # Memoized script directory

COMPRESSION_LEVEL="none"
MAX_TOKENS=0  # 0 = unlimited
CURRENT_TOKEN_COUNT=0

_AST_HELPER_SUPPORTED_LANGS=("python" "javascript" "js" "typescript" "java" "rust" "c" "cpp" "go" "ruby" "php" "csharp")

PRIORITY_EXTENSIONS=(".py" ".js" ".ts" ".md" ".sh" ".cpp" ".h" ".java" ".go" ".rs")
SEMANTIC_EXCLUDES=( "*.min.js" "*.min.css" "*.bundle.*" "*lock*" "*.log" "*cache*" "*dist/*" "*build/*" "*.pyc" "*__pycache__*" "*generated*" "*vendor/*" "*node_modules/*" "*.png" "*.jpg" "*.jpeg" "*.gif" "*.bmp" "*.tiff" "*.ico" "*.svg" "*.zip" "*.tar" "*.gz" "*.bz2" "*.rar" "*.7z" "*.tgz" "*.pdf" "*.doc" "*.docx" "*.xls" "*.xlsx" "*.ppt" "*.pptx" "*.odt" "*.ods" "*.odp" "*.o" "*.a" "*.so" "*.dll" "*.exe" "*.jar" "*.class" "*.swp" "*.bak" "*.tmp" "*.DS_Store" "*.iml" "*.ipr" "*.iws" ".idea/*" ".vscode/*" "*.beam" "*.elf" "*.mp3" "*.mp4" "*.avi" "*.mov" "*.wav" "*.webm" "*.db" "*.sqlite" "*.sqlite3" "*.dump" "*.woff" "*.woff2" "*.ttf" "*.eot" "*/.git/*" ".git" "*/.hg/*" ".hg" "*/.svn/*" ".svn" )
PAK_ID_LINE_PREFIX="__PAK_ID__:"
PAK_UUID_LINE_PREFIX="__PAK_UUID__:"
PAK_FILE_START_PREFIX="__PAK_FILE_"
PAK_DATA_START_PREFIX="__PAK_DATA_"
PAK_DATA_END_PREFIX="__PAK_DATA_"
PAK_FILE_START=""
PAK_DATA_START=""
PAK_DATA_END=""

_PAK_SCRIPT_NAME=$(basename "$0")
_log_prefix="$_PAK_SCRIPT_NAME:"
log_info() { echo "${_log_prefix} info: $@" >&2; }
log_warn() { echo "${_log_prefix} warn: $@" >&2; }
log_error() { echo "${_log_prefix} error: $@" >&2; } 
log_debug() { if [ -n "$PAK_DEBUG" ]; then echo "${_log_prefix} debug: $@" >&2; fi; }

define_markers() { local id="$1"; PAK_FILE_START="${PAK_FILE_START_PREFIX}${id}_START__"; PAK_DATA_START="${PAK_DATA_START_PREFIX}${id}_START__"; PAK_DATA_END="${PAK_DATA_END_PREFIX}${id}_END__"; log_debug "Markers defined for ID: $id"; }
determine_and_cache_ast_status() { if [ "$_AST_STATUS_DETERMINED" = "false" ]; then _CACHED_AST_STATUS=$(check_ast_support_readonly); _AST_STATUS_DETERMINED="true"; log_info "AST support status determined: $_CACHED_AST_STATUS"; else log_debug "AST support status was already determined: $_CACHED_AST_STATUS"; fi; }
get_determined_ast_status() { if [ "$_AST_STATUS_DETERMINED" = "false" ]; then log_warn "AST status accessed before explicit global determination. Checking now."; determine_and_cache_ast_status; fi; echo "$_CACHED_AST_STATUS"; }
auto_install_ast() { log_warn "üîç AST compression requested but not available"; log_info "üì¶ Auto-installing dependencies..."; log_info "üîß Attempting installation with pip3..."; local pip_cmd="pip3"; if $pip_cmd install --user tree-sitter tree-sitter-languages tree-sitter-python; then log_info "‚úÖ AST dependencies installed with pip3 --user."; elif $pip_cmd install --break-system-packages tree-sitter tree-sitter-languages tree-sitter-python; then log_info "‚úÖ AST dependencies installed with pip3 --break-system-packages."; elif $pip_cmd install tree-sitter tree-sitter-languages tree-sitter-python; then log_info "‚úÖ AST dependencies installed with plain pip3 (might require sudo if not in venv)."; else log_error "‚ùå All pip3 installation methods failed for AST dependencies."; log_info "üîß Try manual installation: $pip_cmd install --user tree-sitter tree-sitter-languages tree-sitter-python"; return 1; fi; sleep 1; log_debug "Verifying AST installation after attempt..."; if [ "$(check_ast_support_readonly)" = "true" ]; then log_info "‚úÖ AST support now available after installation!"; _CACHED_AST_STATUS="true"; _AST_STATUS_DETERMINED="true"; return 0; else log_error "‚ùå AST verification failed even after installation attempt."; return 1; fi; }
check_ast_support_readonly() { log_debug "Performing read-only check for AST support..."; local python_check_output; python_check_output=$(python3 -c "import sys; sys.stderr.write('pak: debug: AST_CHECK Python attempt\n'); import tree_sitter_python; from tree_sitter import Language, Parser; python_lang_obj = Language(tree_sitter_python.language()); parser = Parser(python_lang_obj); sys.exit(0)" 2>&1); if [ $? -eq 0 ]; then echo "true"; else echo "false"; log_debug "Captured output from AST support check (python_check_output was: $python_check_output)"; fi; }
check_ast_support() { get_determined_ast_status; }
detect_language() { local file="$1"; local extension="${file##*.}"; local filename; filename=$(basename "$file"); local detected_lang="generic"; case "$extension" in py) detected_lang="python" ;; js|mjs) detected_lang="javascript" ;; ts|tsx) detected_lang="typescript" ;; java) detected_lang="java" ;; rs) detected_lang="rust" ;; cpp|cc|cxx|hpp) detected_lang="cpp" ;; c|h) detected_lang="c" ;; go) detected_lang="go" ;; rb) detected_lang="ruby" ;; php) detected_lang="php" ;; cs) detected_lang="csharp" ;; kt) detected_lang="kotlin" ;; swift) detected_lang="swift" ;; scala) detected_lang="scala" ;; sh|bash) detected_lang="bash" ;; md|rst) detected_lang="markdown" ;; txt) detected_lang="text" ;; json) detected_lang="json" ;; xml) detected_lang="xml" ;; html) detected_lang="html" ;; css) detected_lang="css" ;; yaml|yml) detected_lang="yaml" ;; toml) detected_lang="toml" ;; *) if [ -f "$file" ]; then local first_lines; first_lines=$(head -n 5 "$file" 2>/dev/null); if echo "$first_lines" | grep -q "#!/usr/bin/env python\|# -*- coding: utf-8 -*-"; then detected_lang="python"; elif echo "$first_lines" | grep -q "#!/bin/bash\|#!/bin/sh"; then detected_lang="bash"; elif echo "$first_lines" | grep -Fq "$(printf '%s' '<?php')"; then detected_lang="php"; fi; fi ;; esac; log_debug "Detected language for '$file': $detected_lang"; echo "$detected_lang"; }
is_lang_ast_supported_by_helper() { local lang_to_check="$1"; for supported_lang in "${_AST_HELPER_SUPPORTED_LANGS[@]}"; do if [ "$lang_to_check" = "$supported_lang" ]; then return 0; fi; done; return 1; }

compress_with_ast() {
    local file="$1"; local level="$2"; local language="$3"
    log_debug "compress_with_ast: file='$file', level='$level', language='$language'"
    if [ -z "$_PAK_SCRIPT_DIR" ]; then _PAK_SCRIPT_DIR="$(dirname "$(readlink -f "$0")")"; fi
    local ast_helper_script="$_PAK_SCRIPT_DIR/ast_helper.py"
    local use_ast_helper_for_this_file=false

    if [ -f "$ast_helper_script" ] && [ "$(get_determined_ast_status)" = "true" ]; then
        if is_lang_ast_supported_by_helper "$language"; then
            use_ast_helper_for_this_file=true
        else
            log_info "Language '$language' for '$file' not in ast_helper.py's explicit support list. Using shell text compression."
        fi
    elif [ ! -f "$ast_helper_script" ]; then
        log_warn "ast_helper.py not found. AST compression unavailable for '$file'."
    elif [ "$(get_determined_ast_status)" != "true" ]; then
        log_warn "AST support (Python libs) not available. AST compression unavailable for '$file'."
    fi

    if [ "$use_ast_helper_for_this_file" = "true" ]; then
        log_info "Attempting AST compression for '$file' via ast_helper.py." # Changed to info for visibility
        local helper_output
        helper_output=$(python3 "$ast_helper_script" "$file" "$level" "$language")
        if [ $? -eq 0 ]; then
            printf "%s" "$helper_output"
            return 0 
        else
            log_warn "ast_helper.py script failed (exit code $?) for '$file'. Using shell text-based fallback."
        fi
    fi
    
    log_info "Using shell text-based compression for '$file' (level: $level, lang: $language)."
    case "$level" in
        "light") compress_content_light "$file" ;;
        "medium") compress_content_medium "$file" ;;
        "aggressive") compress_content_aggressive "$file" ;;
        *) cat "$file" ;;
    esac
}

estimate_tokens() { local file="$1"; if [ -f "$file" ]; then local size; if command -v stat &> /dev/null; then size=$(stat -c%s "$file" 2>/dev/null || echo "0"); else size=$(wc -c < "$file" 2>/dev/null || echo "0"); fi; echo $((size / 4)); else echo "0"; fi; }
calculate_file_importance() { local file="$1"; local score=0; local filename; filename=$(basename "$file"); local extension="${filename##*.}"; case ".$extension" in .py|.js|.ts|.cpp|.h|.java|.go|.rs) score=$((score + 10)) ;; .md|.rst) if [[ "$filename" =~ ^(README|readme|CHANGELOG) ]]; then score=$((score + 15)); else score=$((score + 5)); fi ;; .sh|.bash) score=$((score + 8)) ;; .json|.yml|.yaml|.toml) score=$((score + 3)) ;; *) score=$((score + 1)) ;; esac; if [[ "$filename" =~ ^(main|index|app|core|setup|config|dockerfile|makefile|requirements|package\.json|gemfile|build\.gradle)($|\.) ]]; then score=$((score + 7)); fi; if [[ "$file" =~ (test|Test|spec|fixture|mock|stub) ]]; then score=$((score - 5)); fi; if [ "$score" -lt 0 ]; then score=0; fi; log_debug "Importance for '$file': $score"; echo "$score"; }
matches_semantic_excludes() { local file_path="$1"; for pattern in "${SEMANTIC_EXCLUDES[@]}"; do if [[ "$file_path" == $pattern ]]; then log_debug "File '$file_path' matches semantic exclude pattern '$pattern'."; return 0; fi; done; return 1; }
PACK_INCLUDE_EXTENSIONS=()
matches_extension_filter() { local file="$1"; if [ ${#PACK_INCLUDE_EXTENSIONS[@]} -eq 0 ]; then return 0; fi; local filename_only; filename_only=$(basename "$file"); for ext_filter_item in "${PACK_INCLUDE_EXTENSIONS[@]}"; do if [[ "$ext_filter_item" == .* ]]; then if [[ "$filename_only" == *"$ext_filter_item" ]]; then return 0; fi; else if [[ "$filename_only" == "$ext_filter_item" ]] || [[ "$filename_only" == *".$ext_filter_item" ]]; then return 0; fi; fi; done; log_debug "File '$file' did not match extension filters: ${PACK_INCLUDE_EXTENSIONS[*]}"; return 1; }
compress_content_light() { local file_path_or_stdin="$1"; log_debug "compress_content_light for '$file_path_or_stdin'"; sed -E '/^[[:space:]]*$/d' "$file_path_or_stdin" | sed -E 's/^[[:space:]]+//' | sed -E 's/[[:space:]]+$//'; }
compress_content_medium() { local file="$1"; log_debug "compress_content_medium for '$file'"; local extension="${file##*.}"; local ext_lower; ext_lower=$(echo "$extension" | tr '[:upper:]' '[:lower:]'); case "$ext_lower" in py|js|ts|java|c|cpp|h|cs|go|rs|php|rb|pl|swift|kt|kts|sh|bash|markdown|md|rst|text|txt) sed -E -e '1{/^#![^\n]*$/b}' -e '/^[[:space:]]*\/\//d' -e '/^[[:space:]]*#/d' -e '/^[[:space:]]*\/\*.*\*\//d' -e '/^[[:space:]]*<!--.*-->/d' "$file" | compress_content_light /dev/stdin ;; *) compress_content_light "$file" ;; esac; }
compress_content_aggressive() { local file="$1"; log_debug "compress_content_aggressive for '$file'"; local extension="${file##*.}"; local ext_lower; ext_lower=$(echo "$extension" | tr '[:upper:]' '[:lower:]'); local content=""; local script_dir; if [ -z "$_PAK_SCRIPT_DIR" ]; then _PAK_SCRIPT_DIR="$(dirname "$(readlink -f "$0")")"; fi; script_dir="$_PAK_SCRIPT_DIR"; local python_extractor="$script_dir/python_extractor.py"; case "$ext_lower" in py) log_info "Aggressive (text): Attempting Python structure extraction for '$file' via script."; if [ -f "$python_extractor" ]; then log_debug "Using python_extractor.py: $python_extractor"; content=$(python3 "$python_extractor" "$file" 2>/dev/null); else log_warn "Aggressive (text): python_extractor.py not found at '$python_extractor' for '$file'. Using grep fallback."; content=$(grep -E '^[[:space:]]*(import |from |class |def |[A-Z_][A-Z0-9_]*[[:space:]]*=)' "$file" | head -n 100); fi; if [ -z "$content" ] && [ -s "$file" ]; then log_warn "Aggressive (text): Python extraction (script/grep) failed for non-empty '$file'. Using head fallback."; content=$(head -n 50 "$file"); elif [ -z "$content" ]; then log_debug "Aggressive (text): Python extraction (script/grep) resulted in empty content for '$file' (possibly empty or no matches)."; fi ;; js|ts) content=$(grep -Eahn --text '^[[:space:]]*(function |const |let |var |export |import |class |@|/\*\*|\*/|[[:space:]]*//[[:space:]]*(TODO|FIXME|NOTE|OPTIMIZE|IMPORTANT|HACK|XXX))' "$file" | head -n 100) ;; c|cpp|h|java|go|rs|cs) content=$(grep -Eahn --text '^[[:space:]]*(public |private |protected |static |final |func |fn |void |int |long |char |string |struct |class |interface |enum |package |import |#include|#pragma|/\*\*|\*/|[[:space:]]*//[[:space:]]*(TODO|FIXME|NOTE|OPTIMIZE|IMPORTANT|HACK|XXX))' "$file" | head -n 100) ;; md|rst|markdown) content=$(head -n 150 "$file") ;; sh|bash) content=$(grep -Ev '^[[:space:]]*#|^[[:space:]]*$' "$file" | head -n 100) ;; json|yml|yaml|toml|xml|html|css|text|txt) content=$(head -n 200 "$file") ;; *) log_debug "Aggressive (text): File type '$ext_lower' for '$file' not specifically handled, falling back to medium."; compress_content_medium "$file"; return ;; esac; if [ -z "$content" ] && [ -s "$file" ]; then log_warn "Aggressive (text): Produced empty content for non-empty file '$file'. Falling back to medium."; compress_content_medium "$file"; else echo "$content"; fi; }

pack_file() {
    local file="$1"; local current_archive_id="$2"; local size lines compressed_content estimated_tokens language
    log_debug "pack_file: Initiating for '$file'."
    if ! size=$(stat -c%s "$file" 2>/dev/null || wc -c < "$file" 2>/dev/null); then log_warn "Could not get size for '$file'. Skipping."; return; fi
    log_debug "pack_file: Original size for '$file': $size bytes."
    language=$(detect_language "$file"); local archive_method_field="unknown" 
    local successfully_used_ast_helper=false

    if [ "$size" -eq 0 ]; then
        compressed_content=""; archive_method_field="raw (empty file)"
    else
        local is_text=false
        if command -v file &> /dev/null; then if LANG=C file "$file" | grep -q "text\|empty"; then is_text=true; fi
        else case "${file##*.}" in py|js|ts|md|sh|cpp|h|java|go|rs|json|yml|yaml|toml|txt|xml|html|css|c|cs|php|rb|pl|swift|kt|kts) is_text=true ;; esac; fi
        log_debug "pack_file: File '$file' is_text=$is_text"

        if ! $is_text; then
            archive_method_field="raw (non-text)"; if [ "$COMPRESSION_LEVEL" != "none" ]; then log_info "Skipping compression for non-text file '$file'. Adding raw content."; fi
            compressed_content=$(cat "$file")
        elif [ "$COMPRESSION_LEVEL" = "none" ]; then
            archive_method_field="raw (text, no_comp)"; compressed_content=$(cat "$file")
        elif [[ "$COMPRESSION_LEVEL" =~ ^(light|medium|aggressive)$ ]]; then
            log_debug "pack_file: Attempting $COMPRESSION_LEVEL compression for '$file' (lang: $language)"
            # Try AST path first if applicable
            if [ "$(get_determined_ast_status)" = "true" ] && is_lang_ast_supported_by_helper "$language"; then
                if local_helper_output=$(compress_with_ast "$file" "$COMPRESSION_LEVEL" "$language"); then
                     # compress_with_ast returns 0 if ast_helper.py was successful
                    compressed_content="$local_helper_output"
                    archive_method_field="AST-enabled (via helper)"
                    successfully_used_ast_helper=true 
                else
                    # compress_with_ast already logged fallback to shell, or ast_helper.py failed and compress_with_ast used shell
                    # So, content is already set by compress_with_ast's internal shell fallback
                    compressed_content="$local_helper_output" # Capture output from shell fallback within compress_with_ast
                    archive_method_field="text-based (AST helper failed or lang not AST)"
                fi
            else # AST not available or language not supported by helper's AST
                archive_method_field="text-based (AST off or lang not AST)"
                compressed_content=$(compress_with_ast "$file" "$COMPRESSION_LEVEL" "$language") # Will use shell methods
            fi
        else
            log_warn "pack_file: Unexpected COMPRESSION_LEVEL '$COMPRESSION_LEVEL' for '$file'. Treating as 'none'."
            archive_method_field="raw (text, unknown_comp_level)"; compressed_content=$(cat "$file")
        fi
    fi

    estimated_tokens=$(printf "%s" "$compressed_content" | wc -c | awk '{print int($1/4)}')
    if [ "$MAX_TOKENS" -gt 0 ] && [ $((CURRENT_TOKEN_COUNT + estimated_tokens)) -gt "$MAX_TOKENS" ]; then log_info "Token limit: Skipping '$file' (Limit: $MAX_TOKENS, Current: $CURRENT_TOKEN_COUNT, File est: $estimated_tokens, Needed: $((CURRENT_TOKEN_COUNT + estimated_tokens)))." >&2; return; fi
    CURRENT_TOKEN_COUNT=$((CURRENT_TOKEN_COUNT + estimated_tokens))
    lines=$(printf "%s" "$compressed_content" | wc -l)
    
    # Log final packing info for the file
    log_info "Packing '$file': Lang=$language, Size=$size, Lines=$lines, Tokens=$estimated_tokens, Comp=$COMPRESSION_LEVEL, Method=$archive_method_field"
    
    echo "$PAK_FILE_START"; echo "Path: $file"; echo "Language: $language"; echo "Size: $size"; echo "Lines: $lines"; echo "Tokens: $estimated_tokens"; echo "Compression: $COMPRESSION_LEVEL"; echo "Method: $archive_method_field"; echo "$PAK_DATA_START"
    printf "%s" "$compressed_content"
    if [ -n "$compressed_content" ]; then if ! [[ "${compressed_content: -1}" == $'\n' ]]; then echo; fi; else echo; fi
    echo "$PAK_DATA_END"
}

archive_id_for_session=""
pack_smart() { local files_and_dirs_to_pack=("$@"); local file_list=() importance_list=(); log_debug "pack_smart: Input items: ${files_and_dirs_to_pack[*]}"; for item in "${files_and_dirs_to_pack[@]}"; do if [ -f "$item" ]; then if ! matches_semantic_excludes "$item" && matches_extension_filter "$item"; then local importance; importance=$(calculate_file_importance "$item"); local original_tokens; original_tokens=$(estimate_tokens "$item"); importance_list+=("$importance:$original_tokens:$item"); log_debug "pack_smart: Considered file '$item', importance $importance, tokens $original_tokens"; else log_debug "pack_smart: Skipped file '$item' due to semantic/extension exclude."; fi; elif [ -d "$item" ]; then log_debug "pack_smart: Scanning directory '$item'"; find_exclude_opts=(-path "*/.git" -o -path "*/.hg" -o -path "*/.svn" -o -name "*.pak"); while IFS= read -r -d '' file; do if ! matches_semantic_excludes "$file" && matches_extension_filter "$file"; then local importance; importance=$(calculate_file_importance "$file"); local original_tokens; original_tokens=$(estimate_tokens "$file"); importance_list+=("$importance:$original_tokens:$file"); log_debug "pack_smart: Considered file '$file' from dir '$item', importance $importance, tokens $original_tokens"; else log_debug "pack_smart: Skipped file '$file' from dir '$item' due to semantic/extension exclude."; fi; done < <(find "$item" \( "${find_exclude_opts[@]}" \) -prune -o -type f -print0); else log_warn "pack_smart: Item '$item' is not a file or directory. Skipping."; fi; done; IFS=$'\n' sorted_files=($(printf '%s\n' "${importance_list[@]}" | sort -t: -k1,1nr -k2,2n)); unset IFS; log_info "Found ${#sorted_files[@]} files matching filters. Smart Mode (Budget: $([ "$MAX_TOKENS" -eq 0 ] && echo "unlimited" || echo "$MAX_TOKENS") tokens)."; for entry in "${sorted_files[@]}"; do local importance="${entry%%:*}"; local original_tokens_for_entry="${entry#*:}"; original_tokens_for_entry="${original_tokens_for_entry%%:*}"; local filepath="${entry##*:}"; local temp_compression_level; local initial_compression_level_for_smart="light"; if [ "$MAX_TOKENS" -gt 0 ]; then local remaining_budget=$((MAX_TOKENS - CURRENT_TOKEN_COUNT)); if [ "$remaining_budget" -le 0 ]; then log_info "Token budget exhausted in smart mode."; break; fi; if [ "$importance" -lt 5 ] || ( [ "$importance" -lt 8 ] && [ "$original_tokens_for_entry" -gt $((remaining_budget / 3)) ] ); then temp_compression_level="aggressive"; elif [ "$importance" -lt 8 ] || ( [ "$importance" -lt 10 ] && [ "$original_tokens_for_entry" -gt $((remaining_budget / 2)) ] ); then temp_compression_level="medium"; else temp_compression_level="$initial_compression_level_for_smart"; fi; else if [ "$importance" -lt 5 ]; then temp_compression_level="aggressive"; elif [ "$importance" -lt 8 ]; then temp_compression_level="medium"; else temp_compression_level="$initial_compression_level_for_smart"; fi; fi; log_info "Smart: Applying '$temp_compression_level' to '$filepath' (Importance: $importance, Orig.Tokens: $original_tokens_for_entry)."; local original_script_compression_level_backup="$COMPRESSION_LEVEL"; COMPRESSION_LEVEL="$temp_compression_level"; pack_file "$filepath" "$archive_id_for_session"; COMPRESSION_LEVEL="$original_script_compression_level_backup"; if [ "$MAX_TOKENS" -gt 0 ] && [ "$CURRENT_TOKEN_COUNT" -ge "$MAX_TOKENS" ]; then log_info "Token limit reached in smart mode. Processed up to '$filepath'."; break; fi; done; }
pack() { PACK_INCLUDE_EXTENSIONS=(); local final_files_dirs_to_pack=(); local using_smart_mode=false; if [ "$COMPRESSION_LEVEL" = "smart" ]; then using_smart_mode=true; fi; local args_for_pack_function_processing=("$@"); log_debug "pack: Initial args for processing: ${args_for_pack_function_processing[*]}"; while [ "${#args_for_pack_function_processing[@]}" -gt 0 ]; do local arg="${args_for_pack_function_processing[0]}"; case "$arg" in --ext) unset 'args_for_pack_function_processing[0]'; args_for_pack_function_processing=("${args_for_pack_function_processing[@]}"); if [ "${#args_for_pack_function_processing[@]}" -eq 0 ] || [[ "${args_for_pack_function_processing[0]}" == --* ]]; then log_error "--ext requires at least one extension argument (e.g., .py .md)"; exit 1; fi; while [ "${#args_for_pack_function_processing[@]}" -gt 0 ] && ! [[ "${args_for_pack_function_processing[0]}" == --* ]]; do PACK_INCLUDE_EXTENSIONS+=("${args_for_pack_function_processing[0]}"); unset 'args_for_pack_function_processing[0]'; args_for_pack_function_processing=("${args_for_pack_function_processing[@]}"); done; log_debug "pack: Updated PACK_INCLUDE_EXTENSIONS: ${PACK_INCLUDE_EXTENSIONS[*]}" ;; *) final_files_dirs_to_pack+=("$arg"); unset 'args_for_pack_function_processing[0]'; args_for_pack_function_processing=("${args_for_pack_function_processing[@]}") ;; esac; done; log_debug "pack: Final files/dirs to pack: ${final_files_dirs_to_pack[*]}"; if [ "${#final_files_dirs_to_pack[@]}" -eq 0 ]; then log_error "Usage: $_PAK_SCRIPT_NAME --pack [GLOBAL_OPTS] [--ext .ext1] <files/dirs>"; exit 1; fi; archive_id_for_session=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c 12); if [ -z "$archive_id_for_session" ]; then log_error "Failed to generate Archive ID."; exit 1; fi; 
    define_markers "$archive_id_for_session"; echo "${PAK_ID_LINE_PREFIX}${archive_id_for_session}"; echo "# Archive created with pak v$VERSION"; echo "# Archive ID: $archive_id_for_session"; echo "# Compression Mode: $COMPRESSION_LEVEL"; echo "# AST Support: $([ "$(get_determined_ast_status)" = "true" ] && echo "enabled" || echo "disabled")"; if [ "${#PACK_INCLUDE_EXTENSIONS[@]}" -gt 0 ]; then echo "# Extension Filter: ${PACK_INCLUDE_EXTENSIONS[*]}"; fi; if [ "$MAX_TOKENS" -gt 0 ]; then echo "# Token Limit: $MAX_TOKENS"; fi; if $using_smart_mode; then pack_smart "${final_files_dirs_to_pack[@]}"; else for item in "${final_files_dirs_to_pack[@]}"; do log_debug "pack: Processing item '$item' in standard mode."; if [ -f "$item" ]; then if ! matches_semantic_excludes "$item" && matches_extension_filter "$item"; then pack_file "$item" "$archive_id_for_session"; else log_debug "pack: Skipped file '$item' due to semantic/extension exclude."; fi; elif [ -d "$item" ]; then log_debug "pack: Scanning directory '$item' in standard mode."; find_exclude_opts=(-path "*/.git" -o -path "*/.hg" -o -path "*/.svn" -o -name "*.pak"); while IFS= read -r -d '' file; do if ! matches_semantic_excludes "$file" && matches_extension_filter "$file"; then pack_file "$file" "$archive_id_for_session"; else log_debug "pack: Skipped file '$file' from dir '$item' due to semantic/extension exclude."; fi; done < <(find "$item" \( "${find_exclude_opts[@]}" \) -prune -o -type f -print0); else log_warn "pack: Item '$item' is not a file or directory. Skipping."; fi; if [ "$MAX_TOKENS" -gt 0 ] && [ "$CURRENT_TOKEN_COUNT" -ge "$MAX_TOKENS" ]; then log_info "Token limit reached. Halting packing."; break; fi; done; fi; log_info "Archive complete. Total estimated tokens: $CURRENT_TOKEN_COUNT"; }
list_archive() { local archive_file="$1"; log_info "Listing archive '$archive_file'..."; if [ ! -f "$archive_file" ]; then log_error "Archive file not found: $archive_file"; exit 1; fi; local first_line; read -r first_line < "$archive_file"; local archive_id_from_file=""; if [[ "$first_line" == "${PAK_ID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_ID_LINE_PREFIX}}"; elif [[ "$first_line" == "${PAK_UUID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_UUID_LINE_PREFIX}}"; log_info "Reading legacy UUID archive."; else log_error "Not a valid pak archive (missing ID line)."; return 1; fi; if [ -z "$archive_id_from_file" ]; then log_error "Could not extract archive ID."; exit 1; fi; define_markers "$archive_id_from_file"; log_debug "list_archive: Archive ID '$archive_id_from_file'. PAK_FILE_START is '$PAK_FILE_START'"; local awk_script=' /^#.*/ {next} $0 == FILE_START {h=1; p=""; s=""; t=""; lang=""; meth=""; next} h && ($0 ~ /^Path: /) { p=substr($0, length("Path: ")+1); next } h && ($0 ~ /^Size: /) { s=substr($0, length("Size: ")+1); next } h && ($0 ~ /^Tokens: /) { t=substr($0, length("Tokens: ")+1); next } h && ($0 ~ /^Language: /) { lang=substr($0, length("Language: ")+1); next } h && ($0 ~ /^Method: /) { meth=substr($0, length("Method: ")+1); next } h && $0 == DATA_START { if(p){ printf "%s", p; if(s!="") printf " (Size: %s", s; if(t!="") printf ", Tokens: %s", t; if(lang!="") printf ", Lang: %s", lang; if(meth!="") printf ", Method: %s", meth; printf ")\n" } h=0; p="";s="";t="";lang="";meth=""; next} h==0 {next} '; tail -n +2 "$archive_file" | awk -v FILE_START="$PAK_FILE_START" -v DATA_START="$PAK_DATA_START" "$awk_script"; }
verify_archive() { local archive_file="$1"; log_info "Verifying archive '$archive_file'..."; if [ ! -f "$archive_file" ]; then log_error "Archive file not found: $archive_file"; exit 1; fi; local first_line; read -r first_line < "$archive_file"; local archive_id_from_file=""; local fmt_msg="pak v2.2+ (short ID)"; if [[ "$first_line" == "${PAK_ID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_ID_LINE_PREFIX}}"; elif [[ "$first_line" == "${PAK_UUID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_UUID_LINE_PREFIX}}"; fmt_msg="pak v2.0 (UUID)"; log_info "Verifying legacy UUID archive."; else log_error "Not a valid pak archive (missing ID line)."; return 1; fi; if [ -z "$archive_id_from_file" ]; then log_error "Could not extract archive ID."; return 1; fi; log_info "Archive format: $fmt_msg, ID: $archive_id_from_file"; define_markers "$archive_id_from_file"; local total_files=0; local total_declared_tokens=0; local in_header=0; local ast_files=0; local text_files=0; local raw_files=0; { IFS= read -r _; while IFS= read -r line; do if [[ "$line" == "#"* ]] && [ "$in_header" -eq 0 ]; then continue; fi; if [[ "$line" == "$PAK_FILE_START" ]]; then total_files=$((total_files + 1)); in_header=1; elif [[ "$line" == "$PAK_DATA_START" ]]; then in_header=0; elif [[ "$line" == "Tokens: "* ]] && [ "$in_header" -eq 1 ]; then local tokens_val="${line#Tokens: }"; tokens_val="${tokens_val%%[^0-9]*}"; if [[ "$tokens_val" =~ ^[0-9]+$ ]]; then total_declared_tokens=$((total_declared_tokens + tokens_val)); fi; elif [[ "$line" == *"AST"* ]] && [ "$in_header" -eq 1 ]; then ast_files=$((ast_files + 1)); elif [[ "$line" == *"text-based"* ]] && [ "$in_header" -eq 1 ]; then text_files=$((text_files + 1)); elif [[ "$line" == *"raw"* ]] && [ "$in_header" -eq 1 ]; then raw_files=$((raw_files + 1)); fi; done; } < "$archive_file"; log_info "Verification complete: Found $total_files files, total declared tokens: ~$total_declared_tokens"; if [ "$ast_files" -gt 0 ] || [ "$text_files" -gt 0 ] || [ "$raw_files" -gt 0 ]; then log_info "Methods reported: AST-related: $ast_files, Text-based: $text_files, Raw: $raw_files"; fi; } # Adjusted verify log
unpack_archive() { local archive_file="$1"; local outdir="${2:-.}"; log_info "Unpacking '$archive_file' to '$outdir'..."; if [ ! -f "$archive_file" ]; then log_error "Archive file not found: $archive_file"; exit 1; fi; local first_line; read -r first_line < "$archive_file"; local archive_id_from_file=""; if [[ "$first_line" == "${PAK_ID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_ID_LINE_PREFIX}}"; elif [[ "$first_line" == "${PAK_UUID_LINE_PREFIX}"* ]]; then archive_id_from_file="${first_line#${PAK_UUID_LINE_PREFIX}}"; log_info "Unpacking legacy UUID archive."; else log_error "Not a valid pak archive (missing ID line)."; return 1; fi; if [ -z "$archive_id_from_file" ]; then log_error "Could not extract archive ID."; return 1; fi; define_markers "$archive_id_from_file"; if ! mkdir -p "$outdir"; then log_error "Could not create output directory '$outdir'"; exit 1; fi; local current_path=""; local in_data_block=false; local temp_file_for_content=""; { IFS= read -r _; while IFS= read -r line; do if ! $in_data_block && [[ "$line" == "#"* ]]; then continue; fi; if $in_data_block; then if [[ "$line" == "$PAK_DATA_END" ]]; then in_data_block=false; if [ -n "$current_path" ] && [ -n "$temp_file_for_content" ]; then local full_out_path="$outdir/$current_path"; local file_dir; file_dir=$(dirname "$full_out_path"); if ! mkdir -p "$file_dir"; then log_error "Could not create dir '$file_dir'"; rm -f "$temp_file_for_content"; exit 1; fi; if [ -f "$temp_file_for_content" ]; then if mv "$temp_file_for_content" "$full_out_path"; then log_info "Extracted: $full_out_path"; else log_error "mv failed for '$full_out_path'"; rm -f "$temp_file_for_content"; fi; else log_warn "Temp file '$temp_file_for_content' not found for '$current_path'"; fi; temp_file_for_content=""; current_path=""; else log_error "Data end marker found without path or temp file context."; if [ -n "$temp_file_for_content" ] && [ -f "$temp_file_for_content" ]; then rm -f "$temp_file_for_content"; fi; fi; else if [ -n "$temp_file_for_content" ]; then echo "$line" >> "$temp_file_for_content"; fi; fi; elif [[ "$line" == "$PAK_FILE_START" ]]; then current_path=""; if [ -n "$temp_file_for_content" ] && [ -f "$temp_file_for_content" ]; then rm -f "$temp_file_for_content"; fi; temp_file_for_content=$(mktemp "${outdir}/.pak_tmp_XXXXXX"); if [ $? -ne 0 ] || [ -z "$temp_file_for_content" ]; then log_error "mktemp failed. Cannot create temporary file."; exit 1; fi; log_debug "unpack_archive: Created temp file '$temp_file_for_content'"; elif [[ "$line" == "Path: "* ]]; then current_path="${line#Path: }"; current_path=$(echo "$current_path" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//'); log_debug "unpack_archive: Path set to '$current_path'"; elif [[ "$line" == "$PAK_DATA_START" ]]; then if [ -z "$current_path" ]; then log_error "Data start marker found without Path. Archive corrupt or parsing error."; if [ -n "$temp_file_for_content" ]; then rm -f "$temp_file_for_content"; fi; exit 1; fi; if [ -z "$temp_file_for_content" ]; then log_error "Temp file not ready for '$current_path'. Archive corrupt or parsing error."; exit 1; fi; in_data_block=true; log_debug "unpack_archive: Entering data block for '$current_path'"; fi; done; } < "$archive_file"; if [ -n "$temp_file_for_content" ] && [ -f "$temp_file_for_content" ]; then log_debug "unpack_archive: Cleaning up stray temp file '$temp_file_for_content'"; rm -f "$temp_file_for_content"; fi; log_info "Unpack complete."; }

show_ast_info() { echo "pak v$VERSION - AST Enhancement Information"; echo "============================================"; echo ""; local ast_available_now; determine_and_cache_ast_status; ast_available_now=$(get_determined_ast_status); echo "AST Support: $([ "$ast_available_now" = "true" ] && echo "‚úÖ Available" || echo "‚ùå Not available")"; if [ "$ast_available_now" = "true" ]; then echo ""; echo "Supported languages with AST compression (via tree-sitter-languages):"; python3 -c " import tree_sitter_languages; languages = ['python', 'javascript', 'typescript', 'rust', 'java', 'cpp', 'c', 'go', 'ruby', 'php', 'c_sharp']; print('  (Note: Python is loaded via tree_sitter_python directly)'); print('  (Other languages via tree-sitter-languages and listed in _AST_HELPER_SUPPORTED_LANGS in pak3)'); for lang in languages: if lang == 'python': print(f'  ‚úÖ {lang} (direct)'); continue; try: tree_sitter_languages.get_language(lang if lang != 'csharp' else 'c_sharp'); print(f'  ‚úÖ {lang}'); except Exception: print(f'  ‚ùî {lang} (parser might not be available or language name mismatch)'); " 2>/dev/null; echo ""; echo "Compression improvements with AST (estimated vs text-based):"; echo "  ‚Ä¢ Light:      Significant reduction by removing comments/whitespace semantically."; echo "  ‚Ä¢ Medium:     Extracts signatures, class/function definitions."; echo "  ‚Ä¢ Aggressive: Aims for minimal API surface (definitions only)."; echo ""; echo "AST advantages:"; echo "  ‚Ä¢ More accurate removal of non-essential code."; echo "  ‚Ä¢ Potential for language-specific structural compression."; echo "  ‚Ä¢ Fallback to text-based if AST parsing fails for a file (logged)."; else echo ""; echo "To enable AST support:"; echo "  ‚Ä¢ Ensure Python3 and pip are installed."; echo "  ‚Ä¢ Manually install: pip3 install --user tree-sitter tree-sitter-languages tree-sitter-python"; echo "  (Auto-installation can be triggered if dependencies are missing by not using --disable-auto-install)."; if [ -n "$PAK_AUTO_INSTALL" ] && [ "$PAK_AUTO_INSTALL" -eq 0 ]; then echo "  PAK_AUTO_INSTALL is currently disabled by environment variable."; fi; fi; }

if [ "$#" -eq 0 ]; then echo "pak v$VERSION - Token-optimized file archiver for LLMs"; echo ""; echo "Enhanced with AST-based compression:"; echo "  --ast-info             Show AST capabilities and language support"; echo "  --disable-auto-install Disable automatic dependency installation"; echo ""; echo "Usage:"; echo "  Pack:    $_PAK_SCRIPT_NAME [GLOBAL_OPTS] [--pack] [PACK_OPTS] <files/dirs ...> > archive.pak"; echo "  List:    $_PAK_SCRIPT_NAME --ls <archive file>"; echo "  Unpack:  $_PAK_SCRIPT_NAME --unpack <archive file> [--outdir dir]"; echo "  Verify:  $_PAK_SCRIPT_NAME --verify <archive file>"; echo ""; echo "Global Options (can appear anywhere before other commands or pack files):"; echo "  --compress-level LEVEL : none, light, medium, aggressive, smart (default: $COMPRESSION_LEVEL)"; echo "  --max-tokens N         : Limit total tokens in archive (0 for unlimited, default: $MAX_TOKENS)"; echo ""; echo "Pack Command Specific Options (can be mixed with files/dirs for --pack):"; echo "  --ext .ext1 .ext2 ...  : Only include files with these extensions or exact names (e.g., .py .md Makefile)"; echo ""; echo "Examples:"; echo "  $_PAK_SCRIPT_NAME --compress-level smart --max-tokens 16000 src/ --ext .py .md > archive.pak"; echo "  $_PAK_SCRIPT_NAME --pack src/ lib/ --ext .js .css --compress-level aggressive > minimal_frontend.pak"; echo ""; determine_and_cache_ast_status; echo "AST Status: $([ "$(get_determined_ast_status)" = "true" ] && echo "‚úÖ Available" || echo "‚ùå Not available (auto-install might run or manual install may be required)")"; exit 1; fi
declare -a PASSTHROUGH_ARGS=()
COMMAND=""
while [ "$#" -gt 0 ]; do log_debug "Parsing arg: $1"; case "$1" in --compress-level) if [ -z "$2" ]; then log_error "--compress-level requires an argument."; exit 1; fi; COMPRESSION_LEVEL="$2"; if ! [[ "$COMPRESSION_LEVEL" =~ ^(none|light|medium|aggressive|smart)$ ]]; then log_error "Invalid compression level '$COMPRESSION_LEVEL'."; exit 1; fi; shift 2; continue ;; --max-tokens) if [ -z "$2" ] || ! [[ "$2" =~ ^[0-9]+$ ]]; then log_error "--max-tokens requires a non-negative integer."; exit 1; fi; MAX_TOKENS="$2"; shift 2; continue ;; --disable-auto-install) export PAK_AUTO_INSTALL=0; log_info "AST auto-installation disabled by flag."; shift; continue ;; --ast-info) determine_and_cache_ast_status; show_ast_info; exit 0 ;; --help|-h) echo "pak v$VERSION - Token-optimized file archiver for LLMs"; echo ""; echo "Enhanced with AST-based compression:"; echo "  --ast-info             Show AST capabilities and language support"; echo "  --disable-auto-install Disable automatic dependency installation"; echo ""; echo "Usage:"; echo "  Pack:    $_PAK_SCRIPT_NAME [GLOBAL_OPTS] [--pack] [PACK_OPTS] <files/dirs ...> > archive.pak"; echo "  List:    $_PAK_SCRIPT_NAME --ls <archive file>"; echo "  Unpack:  $_PAK_SCRIPT_NAME --unpack <archive file> [--outdir dir]"; echo "  Verify:  $_PAK_SCRIPT_NAME --verify <archive file>"; echo ""; echo "Global Options:"; echo "  --compress-level LEVEL : none, light, medium, aggressive, smart (default: $COMPRESSION_LEVEL)"; echo "  --max-tokens N         : Limit total tokens in archive (0 for unlimited, default: $MAX_TOKENS)"; echo ""; echo "Pack Options:"; echo "  --ext .ext1 .ext2 ...  : Only include files with these extensions"; echo ""; determine_and_cache_ast_status; echo "AST Status: $([ "$(get_determined_ast_status)" = "true" ] && echo "‚úÖ Available" || echo "‚ùå Not available (auto-install might run or manual install may be required)")"; exit 0 ;; --pack|--ls|--unpack|--verify|--version) if [ -n "$COMMAND" ] && [ "$COMMAND" != "$1" ]; then log_warn "Multiple main commands ('$COMMAND' and '$1'). Treating '$1' as an argument."; PASSTHROUGH_ARGS+=("$1"); elif [ -z "$COMMAND" ]; then COMMAND="$1"; else PASSTHROUGH_ARGS+=("$1"); fi; shift ;; *) PASSTHROUGH_ARGS+=("$1"); shift ;; esac; done
if [ -z "$COMMAND" ]; then COMMAND="--pack"; fi
determine_and_cache_ast_status 
if [ "$(get_determined_ast_status)" != "true" ] && [ "${PAK_AUTO_INSTALL:-1}" -eq 1 ]; then log_info "AST support not found, and auto-install is enabled. Attempting to install AST dependencies..."; if ! auto_install_ast; then log_warn "Auto-installation of AST dependencies failed. AST features will not be available for this run."; fi; fi
log_info "Command: $COMMAND"; log_info "Compression: $COMPRESSION_LEVEL, Max Tokens: $MAX_TOKENS"; log_debug "Passthrough args: ${PASSTHROUGH_ARGS[*]}"
case "$COMMAND" in --help|-h) echo "pak v$VERSION ..."; exit 0 ;; --pack) pack "${PASSTHROUGH_ARGS[@]}" ;; --ls) if [ "${#PASSTHROUGH_ARGS[@]}" -ne 1 ]; then log_error "Usage: $_PAK_SCRIPT_NAME --ls <archive file>"; exit 1; fi; list_archive "${PASSTHROUGH_ARGS[0]}" ;; --verify) if [ "${#PASSTHROUGH_ARGS[@]}" -ne 1 ]; then log_error "Usage: $_PAK_SCRIPT_NAME --verify <archive file>"; exit 1; fi; verify_archive "${PASSTHROUGH_ARGS[0]}" ;; --unpack) local archive_to_unpack=""; local unpack_outdir="."; local temp_unpack_args=("${PASSTHROUGH_ARGS[@]}"); if [ "${#temp_unpack_args[@]}" -eq 0 ]; then log_error "Usage: $_PAK_SCRIPT_NAME --unpack <archive file> [--outdir dir]"; exit 1; fi; archive_to_unpack="${temp_unpack_args[0]}"; unset 'temp_unpack_args[0]'; temp_unpack_args=("${temp_unpack_args[@]}"); if [ "${#temp_unpack_args[@]}" -gt 0 ] && [ "${temp_unpack_args[0]}" == "--outdir" ]; then if [ "${#temp_unpack_args[@]}" -lt 2 ]; then log_error "--outdir requires a directory path."; exit 1; fi; unpack_outdir="${temp_unpack_args[1]}"; unset 'temp_unpack_args[0]' 'temp_unpack_args[1]'; temp_unpack_args=("${temp_unpack_args[@]}"); fi; if [ "${#temp_unpack_args[@]}" -gt 0 ]; then log_error "Unknown arguments for --unpack: ${temp_unpack_args[*]}"; exit 1; fi; unpack_archive "$archive_to_unpack" "$unpack_outdir" ;; --version) if [ "${#PASSTHROUGH_ARGS[@]}" -gt 0 ]; then echo "$_PAK_SCRIPT_NAME: warn: --version does not take arguments: ${PASSTHROUGH_ARGS[*]}" >&2; fi; echo "pak version $VERSION"; echo "Features: AST-based compression, token optimization, semantic filtering, smart prioritization"; echo "AST Support: $([ "$(get_determined_ast_status)" = "true" ] && echo "enabled" || echo "disabled (manual install may be required)")" ;; *) log_error "Internal Error: Unhandled command '$COMMAND'. Args: ${PASSTHROUGH_ARGS[*]}"; exit 1 ;; esac
exit 0
